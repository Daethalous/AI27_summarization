# Seq2Seq + Attention 配置文件

# 数据路径
data_dir: ../data/raw
processed_dir: ../data/processed
vocab_path: ../data/processed/vocab.json
save_dir: ./checkpoints
log_path: ./logs/baseline.log
dataset_version: 3.0.0
auto_download: true

# 数据预处理
max_vocab_size: 50000
min_freq: 5
max_src_len: 512
max_tgt_len: 512

# 模型架构
embed_size: 256
hidden_size: 512
num_layers: 1
dropout: 0.1

# 训练超参数
batch_size: 32
num_epochs: 10
learning_rate: 0.0001
grad_clip: 5.0

# Teacher forcing
teacher_forcing_ratio: 0.5

# 其他
seed: 42
